مشروع عملي نظم استرجاع المعلومات
 هيكلية المشروع الأساسية
ir/
│
├── app/                # تطبيق FastAPI - كل Endpoint في ملف مستقل
│   ├── main.py
│   └── endpoints/
│
├── services/
│   ├── clustering/         # منطق الأعمال وخوارزميات التجميع (clustering)
│   ├── retrieval/          # خدمات الاسترجاع (TFIDF, BM25, BERT, Hybrid)
│   ├── vectorization/      # بناء وتحميل النماذج والفيكتور ستور
│   ├── preprocessing/      # خدمات معالجة النصوص (تنظيف، تقطيع، إلخ)
│   ├── rag/                # RAG services
│   ├── indexing/           # فهرسة المستندات
│   ├── evaluation/         # التقييم وتحليل الأداء
│   └── document_store/     # تحميل/تخزين البيانات (داتابيز، SQLite)
│
├── data/
│   ├── clusters/           # تخزين نتائج النماذج والتجميع
│   ├── evaluation_re/      # نتائج التقييم
│   ├── index/              # الفهارس
│   └── vectorizer/         # ملفات تدريب/تمثيل نصوص
│
├── web/
│   ├── app.py              # واجهة المستخدم (Web UI)
│   ├── static/             # ملفات CSS
│   ├── templates/          # ملفات HTML
│   └── utils/              # أدوات تحميل/حفظ المتجهات، وغيرها
│
├── notebooks/              # Jupyter Notebooks (تقييم، Charts، إلخ)
│
├── postman_collection.json # ملفات اختبار الـ APIs
├── README.md
├── requirements.txt        # المكاتب المطلوبة
└── offline_scripts/        # سكربتات خاصة بالتجهيز الـ offline

ش الخدمات الأساسية 
services/document_store/
config.py:
تحديد مصادر البيانات (datasets) ومسارات قواعد البيانات لكل مجموعة بيانات.

loader.py:
تحميل البيانات من مصادرها (مثل ir_datasets)، مع إحصاءات سريعة.

storage.py:
تخزين المستندات الأصلية (doc_id, text) في SQLite Database. دعم تخزين من ملفات نصية أو مصادر خارجية.

معالجة وتخزين النصوص المنظفة:

تحديث الجدول ليحتوي على عدة أعمدة (clean_text_stem, clean_text_bm25, clean_text_bert)، لكل تمثيل نص معالج مختلف.

المعالجة تتم على دفعات (batch) لتحسين الأداء.

services/preprocessing/preprocessor.py
توابع التنظيف:

preprocess_text_and_tokenize:
دالة تنظيف شاملة، مُخصصة للنصوص التي سيتم تمثيلها باستخدام TF-IDF أو خوارزميات تتطلب نصوصًا "نظيفة" قدر الإمكان.


تحويل النص إلى حروف صغيرة (Lowercase)

إزالة علامات الترقيم (Punctuation)

تقطيع النص إلى كلمات (Tokenization)

إزالة الكلمات التوقفية (Stopwords)

حذف الرموز غير الأبجدية (Only alpha)

تطبيق Stemming على الكلمات (PorterStemmer)

إرجاع قائمة من التوكنز النظيفة

preprocess_bm25:
يجب الحفاظ على معظم الكلمات لتقدير الوزن بشكل صحيح حسب BM25.
تحويل النص إلى حروف صغيرة (Lowercase)

إزالة علامات الترقيم (Punctuation)

تقطيع النص على الفراغات فقط (Split)

حذف التوكنز الفارغة فقط (No stopword removal, No stemming)

إرجاع قائمة من التوكنز

preprocess_bert:
يحتاج النص بشكل متسلسل دون تغيير كبير أو فقدان للسياق لانه يعتمد على السياق 
تحويل النص إلى حروف صغيرة (Lowercase)

إزالة علامات الترقيم (Punctuation)

حذف الفراغات الزائدة

إرجاع النص كسلسلة واحدة وليس قائمة توكنز

لقد قمنا بتخصيص خطوات المعالجة النصية لكل تمثيل بناءً على طبيعة الخوارزمية المستخدمة.
فمثلاً، نموذج 
TF-IDF
يحتاج إلى تنظيف عميق للنصوص لإزالة الضجيج والتركيز على الكلمات المفتاحية بينما
BM25 
يعتمد أكثر على تكرار كل كلمة في النص ويستفيد حتى من الكلمات الشائعة، لذا يجب أن تكون المعالجة أخف وأقل حذفًا.
أما نماذج الـ
Embedding (مثل BERT)، 
فهي مصممة لتحليل السياق الكامل للنصوص، وبالتالي يجب تقليل عمليات الحذف والتغيير حتى لا نفقد السياق والمعنى الذي تم تدريب النموذج عليه
هذه الاستراتيجية أدت لتحسين النتائج النهائية لكل تمثيل، وحققت أفضل توافق بين طريقة التمثيل وبين طبيعة البيانات المدخلة


                        
                    شرح تدريبات تمثيل المستندات (Vectorization Training)
هذا القسم جميع عمليات بناء النماذج وتوليد المتجهات
 (vectors) للمستندات "أوفلاين
 "(Offline)
أي قبل مرحلة الاستعلام


هيكلية مسارات الحفظ ملف vector_store
TF-IDF:

النموذج + المتجهات: data/vectorizers/tfidf_{dataset}_model.joblib، tfidf_{dataset}_vectors.joblib

الفهرس المعكوس: data/inverted_index/inverted_index_{dataset}.json

BM25:

النموذج + doc_ids: data/vectorizers/bm25_{dataset}_model.joblib

الفهرس المعكوس: data/inverted_index/inverted_index_{dataset}_bm25.json

BERT/Embedding:

النموذج: data/vectorizers/bert_{dataset}_model.joblib

المتجهات: data/vectorizers/bert_{dataset}_vectors.joblib

خطوات تدريب كل تمثيل
1. TF-IDF Vectorization
وصف العملية:

تحميل جميع المستندات من قاعدة البيانات.

تطبيق دالة التنظيف الخاصة بـ TF-IDF (preprocess_text_and_tokenize) على النصوص.

تدريب نموذج TfidfVectorizer على النصوص المنظفة.

حفظ النموذج والمتجهات (.joblib).

بناء الفهرس المعكوس (Inverted Index) من التوكنز الناتجة وحفظه


2. BM25 Vectorization
وصف العملية:

تحميل المستندات من قاعدة البيانات.

تطبيق دالة تنظيف خفيفة (تتناسب مع BM25).

بناء قائمة قوائم بالتوكنز لكل مستند.

تدريب نموذج BM25Okapi على هذه القوائم.

حفظ النموذج (مع قائمة الـ doc_ids).

بناء الفهرس المعكوس (Inverted Index) من التوكنز وحفظه.


3. BERT Embedding
وصف العملية:

تحميل المستندات من قاعدة البيانات.

تطبيق دالة معالجة بسيطة فقط (Lowercase + حذف الترقيم) للحفاظ على السياق.

تحميل نموذج BERT (all-MiniLM-L6-v2).

توليد متجه embedding لكل مستند باستخدام النموذج.

حفظ النموذج والمتجهات (.joblib).

نماذج الـ Embedding (BERT) تحتاج النص قدر الإمكان كما هو للحفاظ على السياق والمعنى الكامل للجمل.


كل Dataset يتم تدريب التمثيلات عليها بشكل مستقل لضمان عزل الأنظمة والتقييم المنفصل لكل مجموعة بيانات.
بناء الفهارس/المتجهات أوفلاين
حفظ النماذج والمتجهات بصيغة joblib لتسريع التحميل لاحقًا وتقليل استهلاك الذاكرة.

جميع التمثيلات (TF-IDF, BM25, BERT) يتم تدريبها وتخزينها في ملفات منفصلة عن كل داتا سيت، ويتم استخدام النماذج الجاهزة أثناء الاستعلام لضمان أفضل أداء وسرعة



                آلية الاسترجاع (Retrieval) في المشروع


تم بناء نظام استرجاع المعلومات ليكون قابل للتخصيص وقادر على العمل مع أكثر من تمثيل نصي (TF-IDF, BM25, BERT/Embedding, Hybrid)، مع دعم البحث السريع وترتيب 
يتم استدعاء كل خدمة استرجاع عبر واجهة API أو بشكل منفصل داخل النظام.

1. استرجاع باستخدام TF-IDF
آلية العمل:

تحميل نموذج الـT
F-IDF
والمتجهات الجاهزة (offline).

معالجة استعلام المستخدم بنفس دوال التنظيف 
(tokenization + stemming ...).

بناء متجه الاستعلام، واستخدام الفهرس المعكوس لجلب الوثائق المرشحة فقط (تسريع الأداء).

حساب التشابه (Cosine Similarity) بين الاستعلام والوثائق المرشحة فقط.

ترتيب وإرجاع النتائج الأعلى تشابهًا.

ميزات:

استخدام الفهرس المعكوس يقلل زمن الاستعلام بشكل كبير.

تطابق كامل بين معالجة الاستعلام والوثائق.

مرونة بتحديد عدد النتائج المطلوبة.


2. استرجاع باستخدام BM25
آلية العمل:

تحميل نموذج 
BM25 والمتجهات من الملفات الجاهزة.

تطبيق معالجة نصية خفيفة متوافقة مع متطلبات 
BM25.

استخدام الفهرس المعكوس لجلب الوثائق المرشحة 
(matching).

إمكانية تعديل معاملات BM25 (k1, b) أثناء البحث لتجربة التأثير أو تحسين النتائج.

حساب سكور BM25 وترتيب النتائج حسب الأعلى.

ميزات:

دعم متقدم للفهرسة والتصفية الأولية (candidate selection).

إمكانية ضبط المعاملات في الواجهة أو عبر API لتجربة مرونة BM25.

نتائج مستقرة وسريعة.

3. استرجاع باستخدام Embedding (BERT + FAISS/Brute-Force)
آلية العمل:

تحميل نموذج BERT أو SentenceTransformer والمتجهات الجاهزة.

معالجة الاستعلام عبر 
preprocess_bert.

تحويل الاستعلام إلى متجه (vector).

البحث يتم إما:

عبر cosine_similarity (Brute-force)

أو عبر 
FAISS Index 
(في حال تفعيل البحث السريع – مناسب للداتا الضخمة).

ترتيب النتائج حسب أعلى تشابه.

ميزات:

دعم الفهرسة عالية الأداء (FAISS).

مرونة الاختيار بين البحث البسيط أو السريع جدًا (حسب حجم البيانات).

استرجاع دلالي (يأخذ السياق والمعنى الكامل للجملة).

4. الاسترجاع الهجين (Hybrid Retrieval: BM25 + BERT Re-Ranking)
آلية العمل:

المرحلة الأولى: استخدام 
BM25 لجلب مجموعة من أفضل المرشحين (مثلاً 100 وثيقة).

المرحلة الثانية: إعادة ترتيب هؤلاء المرشحين عبر حساب تشابه كل نص مرشح مع الاستعلام بواسطة BERT.

إرجاع أفضل النتائج (Top-k) بعد الترتيب الدلالي.

ميزات:

يحقق الجمع بين دقة BM25 وسرعة الفهرسة + قوة BERT في فهم السياق.

نظام قابل للتطوير لتجربة استراتيجيات دمج إضافية.


كل استعلام يُعالَج بطريقة متوافقة مع التمثيل المستخدم 
(TF-IDF، BM25، BERT، Hybrid)، وتتم فلترة المرشحين بشكل سريع وفعال عبر الفهارس، مع إمكانية تعديل المعاملات أو استخدام البحث السريع (FAISS) للبيانات الكبيرة. النظام مصمم ليكون قابل للتخصيص، التقييم والتطوير المستقبلي بسهولة


                            
                            التقييم


1. تقييم TF-IDF
يتم تحميل نموذج الـ TF-IDF والبحث عن كل استعلام في الداتا.

تحسب المقاييس السابقة 
(Precision@10, Recall, MRR, MAP) 
لكل استعلام.

النتائج تحفظ في ملف 
JSON 
منفصل لكل داتا سيت

2. تقييم BM25
تحميل نموذج BM25 والبحث بنفس طريقة الـ TF-IDF.

دعم تغيير معاملات BM25 وتجربة تأثيرها على المقاييس.

النتائج تحفظ وتعرض بنفس الصيغة القياسية.

3. تقييم Embedding (BERT)
دعم البحث باستخدام Brute-force أو FAISS.

المعالجة تتم باستخدام النموذج المدرب مسبقًا.

تحسب كل المقاييس السابقة، ويمكن مقارنة نتائج الطرق المختلفة.

4. تقييم Hybrid (BM25 + BERT)
الاستعلام يمر أولًا عبر BM25 لجلب أفضل 100 مرشح.

إعادة ترتيب المرشحين بالـ BERT.

حساب جميع المقاييس على النتائج النهائية.

المصدر الوحيد للـqrels
الاعتماد الكامل على ملفات qrels الرسمية (وليس queries فقط)،
مما يضمن تقييم علمي سليم وقابل للمقارنة مع أي نظام آخر.


                    Jupyter Notebooks
ضمن المشروع تم إنشاء دفاتر 
Jupyter منفصلة (Notebooks)
 لكل تمثيل من تمثيلات استرجاع المعلومات 
 (TF-IDF, BM25, BERT, Hybrid ...)،
وذلك بهدف تسهيل عملية تقييم النظام، تحليل النتائج،
 ورسم المخططات البيانية لكل نموذج على حدة

 حتوى كل Notebook:

شرح مختصر للتمثيل المختبر 
(TF-IDF, BM25, BERT, Hybrid...).

تحميل النموذج والمتجهات الخاصة بالداتا سيت المطلوبة.

تنفيذ دوال التقييم البرمجية لحساب المقاييس القياسية 
(MAP, MRR, Recall, Precision@10).

عرض النتائج النهائية في جداول، مع إمكانية رسم مخططات توضيحية.

تحليل مختصر لأداء النظام وتفسير النتائج.

(اختياري) تجربة تغييرات على المعاملات أو إعدادات النموذج، وعرض أثرها على القيم.

هدف هذه الدفاتر:
توثيق دقيق لقيم التقييم النهائية لكل تمثيل على كل مجموعة بيانات.

تسهيل عملية المقارنة بين النماذج المختلفة أو نفس النموذج بعد تطويره أو تعديل إعداداته.

تقديم نتائج قابلة للمراجعة والتكرار لأي مشرف أو باحث.

كيفية الاستخدام:
يمكن تشغيل كل Notebook بشكل منفصل.

النتائج تحفظ تلقائيًا أو تعرض ضمن الـ Notebook.

يمكن تصدير الجداول أو المخططات لإرفاقها مع التقرير النهائي.

أمثلة على الدفاتر المتوفرة:
notebooks/tfidf_evaluation.ipynb

notebooks/bm25_evaluation.ipynb

notebooks/bert_evaluation.ipynb

notebooks/hybrid_evaluation.ipynb


                    
                Clustering

تم استخدام خوارزمية 
KMeans 
مع اختبار عدد الكلاسترات عبر مخطط 
Elbow 
بناءً على المخطط، تم اختيار [عدد الكلاسترات المناسب] لتحقيق توازن بين التجانس الداخلي وعدد المجموعات

بعد تطبيق التجميع ودمجه مع نظام البحث، لوحظ أن مؤشرات التقييم الأساسية 
(MAP, Precision@10, ...) **انخفضت**
 مقارنة بالبحث بدون تجميع.
  وهذا يشير إلى أن التجميع لم يحقق تحسنًا عمليًا في جودة الاسترجاع على هذه البيانات 
قد يعود ذلك إلى:
- عدم وجود تكتلات دلالية واضحة بين الوثائق.
- أو أن توزيع الاستعلامات يغطي جميع الداتا بشكل متقارب.
- أو أن الكلاسترينج يقيّد البحث ضمن مجموعات محدودة ويمنع استرجاع وثائق صالحة من مجموعات أخرى.

**لذلك تم الاكتفاء بتحليل الكلاسترينج بشكل منفصل دون دمجه في الخط الأساسي للبحث، مع عرض المخطط والتحليل المناسب.**

> هذا يعكس الالتزام العلمي بالتحقق والتجريب وعدم إضافة أي تحسين إلا عند التأكد من فائدته العملية.


                        Rag

ميزة 
RAG (Retrieval-Augmented Generation):
ما تم تنفيذه:
استخدمت نموذج توليد نصوص 
(T5-small)
 مع مكتبة 
 HuggingFace
  للرد على استعلام المستخدم اعتمادًا فقط على نصوص الوثائق المسترجعة (context).

الآلية:

بعد البحث عن أفضل المستندات المطابقة للاستعلام 
(باستخدام BERT)
يتم تمرير محتوى الوثائق مع الاستعلام إلى نموذج توليد النصوص،

ليولد إجابة طبيعية ومنسقة تعتمد فقط على المعلومات المأخوذة من نتائج البحث.

ميزة إضافية:
اختصرت نص السياق إذا كان طويلًا (4000 حرف) حتى لا يتجاوز النموذج حدود الطول القصوى.



                    ## REST API Endpoints

### كل خدمة بحث منفصلة (modular SOA)
- /search (TF-IDF)
- /bm25 (BM25)
- /search-bert (BERT)
- /vector/vector-search (Vector Store)
- /hybrid (Hybrid Search)
- /rag/rag-search (RAG)
- /process/process (Text Processing)
- /cluster_search/ (Clustering)

### تجربة كل خدمة:
- كل خدمة قابلة للاختبار بشكل منفصل.
- يمكن تجربة الخدمات الإضافية بشكل مستقل أو مجتمع (دمجها مع الأساسي).
- جميع الاستعلامات مدعومة عبر Postman Collection مع أمثلة محفوظة (مرفقة مع المشروع).
- يمكن للمستخدم اختيار مجموعة البيانات (dataset) وطريقة البحث عند كل استعلام.

### تجربة النظام ككل:
- الواجهة تتيح تجربة النظام الأساسي مع أو بدون الميزات الإضافية (حسب المطلوب).
- جميع الـ APIs مصممة بطريقة مستقلة (SOA) ويمكن دمج أو عزل أي خدمة بدون التأثير على بقية النظام.


            واجهة المستخدم (User Interface)

تتضمن هذه المنظومة واجهة ويب تفاعلية مبنية باستخدام 
Flask وHTML/CSS 
وجافاسكريبت بسيط، تتيح لك تجربة محرك البحث وتجريب جميع خوارزميات الاسترجاع المتوفرة في المشروع.

مميزات الواجهة:
مربع بحث مركزي: يمكنك إدخال أي استعلام نصي وتجربة البحث بسهولة.

اختيار مجموعة البيانات: يمكنك الاختيار بين مجموعتي البيانات (antique أو quora) قبل تنفيذ الاستعلام.

اختيار خوارزمية البحث: عبر مجموعة من خيارات Radio Buttons يمكن تحديد الطريقة:

BM25 (استرجاع تقليدي)

BERT (Vector Search) (بحث دلالي)

Hybrid (دمج النتائج من BM25 وBERT)

RAG (استرجاع مع توليد إجابة بالنص)

Top-K: يمكنك تحديد عدد النتائج المراد إرجاعها.

إظهار أوزان الهجين: عند اختيار البحث الهجين يمكنك ضبط وزن كل من BM25 وBERT بشكل مباشر وسهل.

عرض النتائج بشكل بطاقات Cards: كل مستند يظهر مع معلوماته (النص الأصلي، نتيجة الترتيب، التمثيلات المنظّفة،...إلخ).

إظهار زمن التنفيذ: يظهر زمن تنفيذ كل عملية بحث.

تنبيهات واضحة في حال الخطأ (مثل مشاكل الاتصال أو عدم وجود نتائج).

تصميم عصري متجاوب (Responsive) مناسب للعرض على الشاشات الصغيرة والكبيرة.#   I R  
 #   I R  
 